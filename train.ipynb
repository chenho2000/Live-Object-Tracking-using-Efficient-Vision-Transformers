{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.dataset.crop.lasot import parser_lasot\n",
    "from lib.dataset.crop.lasot import par_crop_lasot\n",
    "from lib.dataset.crop.lasot import gen_json_lasot\n",
    "import matplotlib.pyplot as plt\n",
    "from tracking.basic_model.et_tracker import ET_Tracker\n",
    "from tracking.basic_model.cmt_et_tracker import CMT_ET_Tracker\n",
    "from tracking.basic_model.wavelet_et_tracker import WAVE_ET_Tracker\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from __future__ import division\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from easydict import EasyDict as edict\n",
    "from torch.utils.data import Dataset\n",
    "from lib.utils.utils import *\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1209e1f106df83ad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tracking.basic_model.et_tracker import ET_Tracker\n",
    "from tracking.basic_model.cmt_et_tracker import CMT_ET_Tracker\n",
    "from tracking.basic_model.wavelet_et_tracker import WAVE_ET_Tracker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84b3949f86bf226b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# videos = [\"kangaroo\"]\n",
    "# for j in videos:\n",
    "#     for i in tqdm(range(1,21)):\n",
    "#         curr = f\"kangaroo-{i}\"\n",
    "#         par_crop_lasot.crop_video(\"C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT\", j, curr, \"C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT_cropped\\\\crop511\", 511)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102eafa37cd3f64d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# parser_lasot.main(dataDir='C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT', dataCropDir='C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT_cropped')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8429d8b0acbbe7e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gen_json_lasot.main(dataCropDir='C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT_cropped')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd7ee305e2cd6413"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = edict()\n",
    "\n",
    "# ------config for general parameters------\n",
    "config.GPUS = \"0,1,2,3\"\n",
    "config.WORKERS = 32\n",
    "config.PRINT_FREQ = 10\n",
    "config.OUTPUT_DIR = 'logs'\n",
    "config.CHECKPOINT_DIR = 'snapshot'\n",
    "\n",
    "config.ET = edict()\n",
    "config.ET.TRAIN = edict()\n",
    "config.ET.TEST = edict()\n",
    "config.ET.REID = edict()\n",
    "config.ET.TUNE = edict()\n",
    "config.ET.DATASET = edict()\n",
    "config.ET.DATASET.VID = edict()\n",
    "config.ET.DATASET.GOT10K = edict()\n",
    "config.ET.DATASET.COCO = edict()\n",
    "config.ET.DATASET.DET = edict()\n",
    "config.ET.DATASET.LASOT = edict()\n",
    "config.ET.DATASET.YTB = edict()\n",
    "config.ET.DATASET.VISDRONE = edict()\n",
    "config.ET.DATASET.MIX = edict()\n",
    "\n",
    "\n",
    "# own parameters\n",
    "config.ET.DEVICE = 'cuda'\n",
    "\n",
    "# augmentation\n",
    "config.ET.DATASET.SHIFT = 4\n",
    "config.ET.DATASET.SCALE = 0.05\n",
    "config.ET.DATASET.COLOR = 1\n",
    "config.ET.DATASET.FLIP = 0\n",
    "config.ET.DATASET.BLUR = 0\n",
    "config.ET.DATASET.GRAY = 0\n",
    "config.ET.DATASET.MIXUP = 0\n",
    "config.ET.DATASET.CUTOUT = 0\n",
    "config.ET.DATASET.CHANNEL6 = 0\n",
    "config.ET.DATASET.LABELSMOOTH = 0\n",
    "config.ET.DATASET.ROTATION = 0\n",
    "config.ET.DATASET.SHIFTs = 64\n",
    "config.ET.DATASET.SCALEs = 0.18\n",
    "\n",
    "config.ET.DATASET.MIX.DIST = 'beta'\n",
    "config.ET.DATASET.MIX.ALPHA = 1.0\n",
    "config.ET.DATASET.MIX.BETA = 1.0\n",
    "config.ET.DATASET.MIX.MIN = 0\n",
    "config.ET.DATASET.MIX.MAX = 1\n",
    "config.ET.DATASET.MIX.PROB = 1\n",
    "\n",
    "\n",
    "\n",
    "# LaSOT\n",
    "config.ET.DATASET.LASOT.PATH = 'C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT_cropped\\\\crop511'\n",
    "config.ET.DATASET.LASOT.ANNOTATION = 'C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\LaSOT_cropped\\\\train.json'\n",
    "config.ET.DATASET.LASOT.RANGE = 100\n",
    "config.ET.DATASET.LASOT.USE = 34887\n",
    "\n",
    "\n",
    "# train\n",
    "config.ET.TRAIN.SCRATCH = False\n",
    "config.ET.TRAIN.EMA = 0.9998\n",
    "config.ET.TRAIN.NEG_WEIGHT = 0.1\n",
    "config.ET.TRAIN.GROUP = \"resrchvc\"\n",
    "config.ET.TRAIN.EXID = \"setting1\"\n",
    "config.ET.TRAIN.MODEL = \"ET\"\n",
    "config.ET.TRAIN.RESUME = False\n",
    "config.ET.TRAIN.START_EPOCH = 0\n",
    "config.ET.TRAIN.END_EPOCH = 50\n",
    "config.ET.TRAIN.TEMPLATE_SIZE = 128\n",
    "config.ET.TRAIN.SEARCH_SIZE = 256\n",
    "config.ET.TRAIN.STRIDE = 16\n",
    "config.ET.TRAIN.BATCH = 32\n",
    "config.ET.TRAIN.PRETRAIN = 'pretrain.model'\n",
    "config.ET.TRAIN.LR_POLICY = 'log'\n",
    "config.ET.TRAIN.LR = 0.001\n",
    "config.ET.TRAIN.LR_END = 0.00001\n",
    "config.ET.TRAIN.MOMENTUM = 0.9\n",
    "config.ET.TRAIN.WEIGHT_DECAY = 0.0001\n",
    "config.ET.TRAIN.WHICH_USE = ['LASOT']  # VID or 'GOT10K'\n",
    "config.ET.TRAIN.FREEZE_LAYER = []\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e85810c2e2236f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_random = random.Random()\n",
    "\n",
    "\n",
    "class OceanDataset(Dataset):\n",
    "    def __init__(self, cfg):\n",
    "        super(OceanDataset, self).__init__()\n",
    "        # pair information\n",
    "        self.template_size = cfg.ET.TRAIN.TEMPLATE_SIZE\n",
    "        self.search_size = cfg.ET.TRAIN.SEARCH_SIZE\n",
    "\n",
    "        # self.size = 25\n",
    "        self.stride = cfg.ET.TRAIN.STRIDE\n",
    "        self.size = round(self.search_size / self.stride)\n",
    "\n",
    "        # aug information\n",
    "        self.color = cfg.ET.DATASET.COLOR\n",
    "        self.flip = cfg.ET.DATASET.FLIP\n",
    "        self.rotation = cfg.ET.DATASET.ROTATION\n",
    "        self.blur = cfg.ET.DATASET.BLUR\n",
    "        self.shift = cfg.ET.DATASET.SHIFT\n",
    "        self.scale = cfg.ET.DATASET.SCALE\n",
    "        self.gray = cfg.ET.DATASET.GRAY\n",
    "        self.label_smooth = cfg.ET.DATASET.LABELSMOOTH\n",
    "        self.mixup = cfg.ET.DATASET.MIXUP\n",
    "        self.cutout = cfg.ET.DATASET.CUTOUT\n",
    "\n",
    "        # aug for search image\n",
    "        self.shift_s = cfg.ET.DATASET.SHIFTs\n",
    "        self.scale_s = cfg.ET.DATASET.SCALEs\n",
    "\n",
    "        self.grids()\n",
    "\n",
    "        self.transform_extra = transforms.Compose(\n",
    "            [transforms.ToPILImage(), ] +\n",
    "            ([transforms.ColorJitter(0.05, 0.05, 0.05, 0.05), ] if self.color > random.random() else [])\n",
    "            + ([transforms.RandomHorizontalFlip(), ] if self.flip > random.random() else [])\n",
    "            + ([transforms.RandomRotation(degrees=10), ] if self.rotation > random.random() else [])\n",
    "            + ([transforms.Grayscale(num_output_channels=3), ] if self.gray > random.random() else [])\n",
    "            + ([transforms.Cutout(n_holes=1, length=16)] if self.cutout > random.random() else [])\n",
    "        )\n",
    "\n",
    "        # train data information\n",
    "        print('train datas: {}'.format(cfg.ET.TRAIN.WHICH_USE))\n",
    "        self.train_datas = []  # all train dataset\n",
    "        start = 0\n",
    "        self.num = 0\n",
    "        for data_name in cfg.ET.TRAIN.WHICH_USE:\n",
    "            dataset = subData(cfg, data_name, start)\n",
    "            self.train_datas.append(dataset)\n",
    "            start += dataset.num  # real video number\n",
    "            self.num += dataset.num_use  # the number used for subset shuffle\n",
    "\n",
    "        self._shuffle()\n",
    "        print(cfg)\n",
    "\n",
    "        '''normalization'''\n",
    "        mean = [0.485, 0.456, 0.406]  # IMAGENET MEAN (RGB)\n",
    "        std = [0.229, 0.224, 0.225]  # IMAGENET STD (RGB)\n",
    "        self.transform_norm = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        pick a vodeo/frame --> pairs --> data aug --> label\n",
    "        \"\"\"\n",
    "\n",
    "        index = self.pick[index]\n",
    "        dataset, index = self._choose_dataset(index)\n",
    "\n",
    "        template, search = dataset._get_pairs(index, dataset.data_name)\n",
    "        template, search = self.check_exists(index, dataset, template, search)\n",
    "\n",
    "        template_image = cv2.cvtColor(cv2.imread(template[0]), cv2.COLOR_BGR2RGB)  # numpy array\n",
    "        search_image = cv2.cvtColor(cv2.imread(search[0]), cv2.COLOR_BGR2RGB)  # numpy array\n",
    "\n",
    "        template_box = self._toBBox(template_image, template[1])\n",
    "        search_box = self._toBBox(search_image, search[1])\n",
    "\n",
    "        template, tbox, _ = self._augmentation(template_image, template_box, self.template_size)\n",
    "        search, bbox, dag_param = self._augmentation(search_image, search_box, self.search_size, search=True)\n",
    "\n",
    "        # from PIL image to numpy\n",
    "        template = np.array(template)\n",
    "        search = np.array(search)\n",
    "        '''2020.08.13 positive region is adaptive to the stride'''\n",
    "        out_label = self._dynamic_label([self.size, self.size], dag_param.shift,\n",
    "                                        rPos=16 / self.stride)\n",
    "\n",
    "        reg_label, reg_weight = self.reg_label(bbox)\n",
    "\n",
    "        template, search = map(lambda x: np.transpose(x, (2, 0, 1)).astype(np.float32), [template, search])\n",
    "        '''Normalization'''\n",
    "        template, search = map(lambda x: self.transform_norm(torch.tensor(x) / 255.0), [template, search])\n",
    "        return template, search, out_label, reg_label, reg_weight, np.array(bbox, np.float32)  # self.label 15*15/17*17\n",
    "\n",
    "    # ------------------------------------\n",
    "    # function groups for selecting pairs\n",
    "    # ------------------------------------\n",
    "    def grids(self):\n",
    "        \"\"\"\n",
    "        each element of feature map on input search image\n",
    "        :return: H*W*2 (position for each element)\n",
    "        \"\"\"\n",
    "        sz = self.size\n",
    "\n",
    "        sz_x = sz // 2\n",
    "        sz_y = sz // 2\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(0, sz) - np.floor(float(sz_x)),\n",
    "                           np.arange(0, sz) - np.floor(float(sz_y)))\n",
    "\n",
    "        self.grid_to_search = {}\n",
    "        self.grid_to_search_x = x * self.stride + self.search_size // 2\n",
    "        self.grid_to_search_y = y * self.stride + self.search_size // 2\n",
    "        #  (0,0) top left (stride)\n",
    "        ## bbox in 0,0 in pixel coord-system\n",
    "\n",
    "    def reg_label(self, bbox):\n",
    "        \"\"\"\n",
    "        generate regression label\n",
    "        :param bbox: [x1, y1, x2, y2]\n",
    "        :return: [l, t, r, b]\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        l = self.grid_to_search_x - x1  # [17, 17]\n",
    "        t = self.grid_to_search_y - y1\n",
    "        r = x2 - self.grid_to_search_x\n",
    "        b = y2 - self.grid_to_search_y\n",
    "        l, t, r, b = map(lambda x: np.expand_dims(x, axis=-1), [l, t, r, b])\n",
    "        reg_label = np.concatenate((l, t, r, b), axis=-1)  # [17, 17, 4]\n",
    "        reg_label_min = np.min(reg_label, axis=-1)\n",
    "        inds_nonzero = (reg_label_min > 0).astype(float)  # location not inside the box\n",
    "\n",
    "        return reg_label, inds_nonzero\n",
    "\n",
    "    def check_exists(self, index, dataset, template, search):\n",
    "        name = dataset.data_name\n",
    "        while True:\n",
    "            if 'RGBT' in name or 'GTOT' in name and 'RGBTRGB' not in name and 'RGBTT' not in name:\n",
    "                if not (os.path.exists(template[0][0]) and os.path.exists(search[0][0])):\n",
    "                    index = random.randint(0, 100)\n",
    "                    template, search = dataset._get_pairs(index, name)\n",
    "                    continue\n",
    "                else:\n",
    "                    return template, search\n",
    "            else:\n",
    "                #print(f'second case')\n",
    "                if not (os.path.exists(template[0]) and os.path.exists(search[0])):\n",
    "                    print(f'paths do not exist: {template[0]}, {search[0]}')\n",
    "                    index = random.randint(0, 100)\n",
    "                    template, search = dataset._get_pairs(index, name)\n",
    "                    continue\n",
    "                else:\n",
    "                    return template, search\n",
    "\n",
    "    def _shuffle(self):\n",
    "        \"\"\"\n",
    "        random shuffel\n",
    "        \"\"\"\n",
    "        pick = []\n",
    "        m = 0\n",
    "        while m < self.num:\n",
    "            p = []\n",
    "            for subset in self.train_datas:\n",
    "                sub_p = subset.pick\n",
    "                p += sub_p\n",
    "            sample_random.shuffle(p)\n",
    "\n",
    "            pick += p\n",
    "            m = len(pick)\n",
    "        self.pick = pick\n",
    "        print(\"dataset length {}\".format(self.num))\n",
    "\n",
    "    def _choose_dataset(self, index):\n",
    "        for dataset in self.train_datas:\n",
    "            if dataset.start + dataset.num > index:\n",
    "                return dataset, index - dataset.start\n",
    "\n",
    "    def _get_image_anno(self, video, track, frame, RGBT_FLAG=False):\n",
    "        \"\"\"\n",
    "        get image and annotation\n",
    "        \"\"\"\n",
    "\n",
    "        frame = \"{:06d}\".format(frame)\n",
    "        if not RGBT_FLAG:\n",
    "            image_path = join(self.root, video, \"{}.{}.x.jpg\".format(frame, track))\n",
    "            image_anno = self.labels[video][track][frame]\n",
    "            return image_path, image_anno\n",
    "        else:  # rgb\n",
    "            in_image_path = join(self.root, video, \"{}.{}.in.x.jpg\".format(frame, track))\n",
    "            rgb_image_path = join(self.root, video, \"{}.{}.rgb.x.jpg\".format(frame, track))\n",
    "            image_anno = self.labels[video][track][frame]\n",
    "            in_anno = np.array(image_anno[-1][0])\n",
    "            rgb_anno = np.array(image_anno[-1][1])\n",
    "\n",
    "            return [in_image_path, rgb_image_path], (in_anno + rgb_anno) / 2\n",
    "\n",
    "    def _get_pairs(self, index):\n",
    "        \"\"\"\n",
    "        get training pairs\n",
    "        \"\"\"\n",
    "        video_name = self.videos[index]\n",
    "        video = self.labels[video_name]\n",
    "        track = random.choice(list(video.keys()))\n",
    "        track_info = video[track]\n",
    "        try:\n",
    "            frames = track_info['frames']\n",
    "        except:\n",
    "            frames = list(track_info.keys())\n",
    "\n",
    "        template_frame = random.randint(0, len(frames) - 1)\n",
    "\n",
    "        left = max(template_frame - self.frame_range, 0)\n",
    "        right = min(template_frame + self.frame_range, len(frames) - 1) + 1\n",
    "        search_range = frames[left:right]\n",
    "        template_frame = int(frames[template_frame])\n",
    "        search_frame = int(random.choice(search_range))\n",
    "\n",
    "        return self._get_image_anno(video_name, track, template_frame), \\\n",
    "            self._get_image_anno(video_name, track, search_frame)\n",
    "\n",
    "    def _posNegRandom(self):\n",
    "        \"\"\"\n",
    "        random number from [-1, 1]\n",
    "        \"\"\"\n",
    "        return random.random() * 2 - 1.0\n",
    "\n",
    "    def _toBBox(self, image, shape):\n",
    "        '''\n",
    "        image: input image\n",
    "        shape: bounding box\n",
    "        '''\n",
    "        imh, imw = image.shape[:2]\n",
    "        if len(shape) == 4:\n",
    "            w, h = shape[2] - shape[0], shape[3] - shape[1]\n",
    "        else:\n",
    "            w, h = shape\n",
    "\n",
    "        context_amount = 0.5\n",
    "        exemplar_size = self.template_size\n",
    "\n",
    "        wc_z = w + context_amount * (w + h)\n",
    "        hc_z = h + context_amount * (w + h)\n",
    "\n",
    "        s_z = np.sqrt(wc_z * hc_z)\n",
    "        scale_z = exemplar_size / s_z\n",
    "        w = w * scale_z\n",
    "        h = h * scale_z\n",
    "        cx, cy = imw // 2, imh // 2\n",
    "        bbox = center2corner(Center(cx, cy, w, h))\n",
    "        return bbox\n",
    "\n",
    "    def _crop_hwc(self, image, bbox, out_sz, padding=(0, 0, 0)):\n",
    "        \"\"\"\n",
    "        crop image\n",
    "        \"\"\"\n",
    "        bbox = [float(x) for x in bbox]\n",
    "        a = (out_sz - 1) / (bbox[2] - bbox[0])\n",
    "        b = (out_sz - 1) / (bbox[3] - bbox[1])\n",
    "        c = -a * bbox[0]\n",
    "        d = -b * bbox[1]\n",
    "        mapping = np.array([[a, 0, c],\n",
    "                            [0, b, d]]).astype(np.float64)\n",
    "        crop = cv2.warpAffine(image, mapping, (out_sz, out_sz), borderMode=cv2.BORDER_CONSTANT, borderValue=padding)\n",
    "        return crop\n",
    "\n",
    "    def _draw(self, image, box, name):\n",
    "        \"\"\"\n",
    "        draw image for debugging\n",
    "        \"\"\"\n",
    "        draw_image = np.array(image.copy())\n",
    "        x1, y1, x2, y2 = map(lambda x: int(round(x)), box)\n",
    "        cv2.rectangle(draw_image, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "        cv2.circle(draw_image, (int(round(x1 + x2) / 2), int(round(y1 + y2) / 2)), 3, (0, 0, 255))\n",
    "        cv2.putText(draw_image, '[x: {}, y: {}]'.format(int(round(x1 + x2) / 2), int(round(y1 + y2) / 2)),\n",
    "                    (int(round(x1 + x2) / 2) - 3, int(round(y1 + y2) / 2) - 3), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "                    (255, 255, 255), 1)\n",
    "        cv2.imwrite(name, draw_image)\n",
    "\n",
    "    def _draw_reg(self, image, grid_x, grid_y, reg_label, reg_weight, save_path, index):\n",
    "        \"\"\"\n",
    "        visiualization\n",
    "        reg_label: [l, t, r, b]\n",
    "        \"\"\"\n",
    "        draw_image = image.copy()\n",
    "        # count = 0\n",
    "        save_name = join(save_path, '{:06d}.jpg'.format(index))\n",
    "        h, w = reg_weight.shape\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if not reg_weight[i, j] > 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    x1 = int(grid_x[i, j] - reg_label[i, j, 0])\n",
    "                    y1 = int(grid_y[i, j] - reg_label[i, j, 1])\n",
    "                    x2 = int(grid_x[i, j] + reg_label[i, j, 2])\n",
    "                    y2 = int(grid_y[i, j] + reg_label[i, j, 3])\n",
    "\n",
    "                    draw_image = cv2.rectangle(draw_image, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "\n",
    "        cv2.imwrite(save_name, draw_image)\n",
    "\n",
    "    def _mixupRandom(self):\n",
    "        \"\"\"\n",
    "        gaussian random -- 0.3~0.7\n",
    "        \"\"\"\n",
    "        return random.random() * 0.4 + 0.3\n",
    "\n",
    "    # ------------------------------------\n",
    "    # function for data augmentation\n",
    "    # ------------------------------------\n",
    "    def _augmentation(self, image, bbox, size, search=False):\n",
    "        \"\"\"\n",
    "        data augmentation for input pairs\n",
    "        \"\"\"\n",
    "        shape = image.shape\n",
    "        crop_bbox = center2corner((shape[0] // 2, shape[1] // 2, size, size))\n",
    "        param = edict()\n",
    "\n",
    "        if search:\n",
    "            param.shift = (self._posNegRandom() * self.shift_s, self._posNegRandom() * self.shift_s)  # shift\n",
    "            param.scale = (\n",
    "            (1.0 + self._posNegRandom() * self.scale_s), (1.0 + self._posNegRandom() * self.scale_s))  # scale change\n",
    "        else:\n",
    "            param.shift = (self._posNegRandom() * self.shift, self._posNegRandom() * self.shift)  # shift\n",
    "            param.scale = (\n",
    "            (1.0 + self._posNegRandom() * self.scale), (1.0 + self._posNegRandom() * self.scale))  # scale change\n",
    "\n",
    "        crop_bbox, _ = aug_apply(Corner(*crop_bbox), param, shape)\n",
    "\n",
    "        x1, y1 = crop_bbox.x1, crop_bbox.y1\n",
    "        bbox = BBox(bbox.x1 - x1, bbox.y1 - y1, bbox.x2 - x1, bbox.y2 - y1)\n",
    "\n",
    "        scale_x, scale_y = param.scale\n",
    "        bbox = Corner(bbox.x1 / scale_x, bbox.y1 / scale_y, bbox.x2 / scale_x, bbox.y2 / scale_y)\n",
    "\n",
    "        image = self._crop_hwc(image, crop_bbox, size)  # shift and scale\n",
    "\n",
    "        if self.blur > random.random():\n",
    "            image = gaussian_filter(image, sigma=(1, 1, 0))\n",
    "\n",
    "        image = self.transform_extra(image)  # other data augmentation\n",
    "        return image, bbox, param\n",
    "\n",
    "    def _mixupShift(self, image, size):\n",
    "        \"\"\"\n",
    "        random shift mixed-up image\n",
    "        \"\"\"\n",
    "        shape = image.shape\n",
    "        crop_bbox = center2corner((shape[0] // 2, shape[1] // 2, size, size))\n",
    "        param = edict()\n",
    "\n",
    "        param.shift = (self._posNegRandom() * 64, self._posNegRandom() * 64)  # shift\n",
    "        crop_bbox, _ = aug_apply(Corner(*crop_bbox), param, shape)\n",
    "\n",
    "        image = self._crop_hwc(image, crop_bbox, size)  # shift and scale\n",
    "\n",
    "        return image\n",
    "\n",
    "    # ------------------------------------\n",
    "    # function for creating training label\n",
    "    # ------------------------------------\n",
    "    def _dynamic_label(self, fixedLabelSize, c_shift, rPos=2, rNeg=0):\n",
    "        if isinstance(fixedLabelSize, int):\n",
    "            fixedLabelSize = [fixedLabelSize, fixedLabelSize]\n",
    "\n",
    "        # assert (fixedLabelSize[0] % 2 == 1)\n",
    "\n",
    "        d_label = self._create_dynamic_logisticloss_label(fixedLabelSize, c_shift, rPos, rNeg)\n",
    "\n",
    "        return d_label\n",
    "\n",
    "    def _create_dynamic_logisticloss_label(self, label_size, c_shift, rPos=2, rNeg=0):\n",
    "        if isinstance(label_size, int):\n",
    "            sz = label_size\n",
    "        else:\n",
    "            sz = label_size[0]\n",
    "\n",
    "        sz_x = sz // 2 + int(-c_shift[0] / self.stride)  # 8 is strides\n",
    "        sz_y = sz // 2 + int(-c_shift[1] / self.stride)\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(0, sz) - np.floor(float(sz_x)),\n",
    "                           np.arange(0, sz) - np.floor(float(sz_y)))\n",
    "\n",
    "        dist_to_center = np.abs(x) + np.abs(y)  # Block metric\n",
    "        label = np.where(dist_to_center <= rPos,\n",
    "                         np.ones_like(y),\n",
    "                         np.where(dist_to_center < rNeg,\n",
    "                                  0.5 * np.ones_like(y),\n",
    "                                  np.zeros_like(y)))\n",
    "        return label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# for a single dataset\n",
    "# ---------------------\n",
    "\n",
    "class subData(object):\n",
    "    \"\"\"\n",
    "    for training with multi dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, data_name, start):\n",
    "        self.data_name = data_name\n",
    "        self.start = start\n",
    "\n",
    "        info = cfg.ET.DATASET[data_name]\n",
    "        self.frame_range = info.RANGE\n",
    "        self.num_use = info.USE\n",
    "        self.root = info.PATH\n",
    "\n",
    "        with open(info.ANNOTATION) as fin:\n",
    "            self.labels = json.load(fin)\n",
    "            self._clean()\n",
    "            self.num = len(self.labels)  # video numer\n",
    "\n",
    "        self._shuffle()\n",
    "\n",
    "    def _clean(self):\n",
    "        \"\"\"\n",
    "        remove empty videos/frames/annos in dataset\n",
    "        \"\"\"\n",
    "        # no frames\n",
    "        to_del = []\n",
    "        for video in self.labels:\n",
    "            for track in self.labels[video]:\n",
    "                frames = self.labels[video][track]\n",
    "                frames = list(map(int, frames.keys()))\n",
    "                frames.sort()\n",
    "                self.labels[video][track]['frames'] = frames\n",
    "                if len(frames) <= 0:\n",
    "                    print(\"warning {}/{} has no frames.\".format(video, track))\n",
    "                    to_del.append((video, track))\n",
    "\n",
    "        for video, track in to_del:\n",
    "            try:\n",
    "                del self.labels[video][track]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # no track/annos\n",
    "        to_del = []\n",
    "\n",
    "        if self.data_name == 'YTB':\n",
    "            to_del.append('train/1/YyE0clBPamU')  # This video has no bounding box.\n",
    "        print(self.data_name)\n",
    "\n",
    "        for video in self.labels:\n",
    "            if len(self.labels[video]) <= 0:\n",
    "                print(\"warning {} has no tracks\".format(video))\n",
    "                to_del.append(video)\n",
    "\n",
    "        for video in to_del:\n",
    "            try:\n",
    "                del self.labels[video]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        self.videos = list(self.labels.keys())\n",
    "        print('{} loaded.'.format(self.data_name))\n",
    "\n",
    "    def _shuffle(self):\n",
    "        \"\"\"\n",
    "        shuffel to get random pairs index (video)\n",
    "        \"\"\"\n",
    "        lists = list(range(self.start, self.start + self.num))\n",
    "        m = 0\n",
    "        pick = []\n",
    "        while m < self.num_use:\n",
    "            sample_random.shuffle(lists)\n",
    "            pick += lists\n",
    "            m += self.num\n",
    "\n",
    "        self.pick = pick[:self.num_use]\n",
    "        return self.pick\n",
    "\n",
    "    def _get_image_anno(self, video, track, frame):\n",
    "        \"\"\"\n",
    "        get image and annotation\n",
    "        \"\"\"\n",
    "\n",
    "        frame = \"{:06d}\".format(frame)\n",
    "\n",
    "        image_path = join(self.root, video, \"{}.{}.x.jpg\".format(frame, track))\n",
    "        image_anno = self.labels[video][track][frame]\n",
    "        return image_path, image_anno\n",
    "\n",
    "    def _get_pairs(self, index, data_name):\n",
    "        \"\"\"\n",
    "        get training pairs\n",
    "        \"\"\"\n",
    "        video_name = self.videos[index]\n",
    "        video = self.labels[video_name]\n",
    "        track = random.choice(list(video.keys()))\n",
    "        track_info = video[track]\n",
    "        try:\n",
    "            frames = track_info['frames']\n",
    "        except:\n",
    "            frames = list(track_info.keys())\n",
    "\n",
    "        template_frame = random.randint(0, len(frames) - 1)\n",
    "\n",
    "        left = max(template_frame - self.frame_range, 0)\n",
    "        right = min(template_frame + self.frame_range, len(frames) - 1) + 1\n",
    "        search_range = frames[left:right]\n",
    "\n",
    "        template_frame = int(frames[template_frame])\n",
    "        search_frame = int(random.choice(search_range))\n",
    "\n",
    "        return self._get_image_anno(video_name, track, template_frame), \\\n",
    "            self._get_image_anno(video_name, track, search_frame)\n",
    "\n",
    "    def _get_negative_target(self, index=-1):\n",
    "        \"\"\"\n",
    "        dasiam neg\n",
    "        \"\"\"\n",
    "        if index == -1:\n",
    "            index = random.randint(0, self.num - 1)\n",
    "        video_name = self.videos[index]\n",
    "        video = self.labels[video_name]\n",
    "        track = random.choice(list(video.keys()))\n",
    "        track_info = video[track]\n",
    "\n",
    "        frames = track_info['frames']\n",
    "        frame = random.choice(frames)\n",
    "\n",
    "        return self._get_image_anno(video_name, track, frame)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fb1cabff883d216"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasot = OceanDataset(config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94be716a5530bea7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "seed_everything(2000)\n",
    "# Check gpu\n",
    "device = \"mps\" if torch.backends.mps.is_built() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2a1a1294c8d430c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ettracker = ET_Tracker(linear_reg=True)\n",
    "ettracker.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9a793679df323ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(ettracker.parameters(), lr=0.02, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b31ad7c5614674e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(lasot, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4efd07217c87ac72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses = []\n",
    "min_loss = float('inf')\n",
    "for epoch in tqdm(range(10)):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        template, search, out_label, reg_label, reg_weight, some_array = data\n",
    "        template = template.to(device)\n",
    "        search = search.to(device)\n",
    "        out_label = out_label.to(device)\n",
    "        reg_label = reg_label.to(device)\n",
    "        reg_weight = reg_weight.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = ettracker(template, search, out_label, reg_label, reg_weight)\n",
    "        cls, reg = output\n",
    "        loss = cls + reg\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            print(f'Epoch: {epoch}, Batch: {i}, MIN Loss: {loss.item()}')\n",
    "            PATH = './ettracker_min.pth'\n",
    "            torch.save(ettracker.state_dict(), PATH)  # save model to path\n",
    "            continue\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}')\n",
    "    scheduler.step()\n",
    "    \n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "975719d89c80387"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = './ettracker.pth'\n",
    "\n",
    "torch.save(ettracker.state_dict(), PATH)  # save model to path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6ee741de66c4862"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('losses.pkl', 'wb') as f:\n",
    "    pickle.dump(losses, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6c1a298906f07ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parser_lasot.main(dataDir='C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\test\\\\LaSOT', dataCropDir='C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\test\\\\LaSOT_cropped')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53585f8ba8abd9f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen_json_lasot.main(dataCropDir='C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\test\\\\LaSOT_cropped')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f5611ab427b94d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_test = edict()\n",
    "\n",
    "# ------config_test for general parameters------\n",
    "config_test.GPUS = \"0,1,2,3\"\n",
    "config_test.WORKERS = 32\n",
    "config_test.PRINT_FREQ = 10\n",
    "config_test.OUTPUT_DIR = 'logs'\n",
    "config_test.CHECKPOINT_DIR = 'snapshot'\n",
    "\n",
    "config_test.ET = edict()\n",
    "config_test.ET.TRAIN = edict()\n",
    "config_test.ET.TEST = edict()\n",
    "config_test.ET.REID = edict()\n",
    "config_test.ET.TUNE = edict()\n",
    "config_test.ET.DATASET = edict()\n",
    "config_test.ET.DATASET.VID = edict()\n",
    "config_test.ET.DATASET.GOT10K = edict()\n",
    "config_test.ET.DATASET.COCO = edict()\n",
    "config_test.ET.DATASET.DET = edict()\n",
    "config_test.ET.DATASET.LASOT = edict()\n",
    "config_test.ET.DATASET.YTB = edict()\n",
    "config_test.ET.DATASET.VISDRONE = edict()\n",
    "config_test.ET.DATASET.MIX = edict()\n",
    "\n",
    "\n",
    "# own parameters\n",
    "config_test.ET.DEVICE = 'cuda'\n",
    "\n",
    "# augmentation\n",
    "config_test.ET.DATASET.SHIFT = 4\n",
    "config_test.ET.DATASET.SCALE = 0.05\n",
    "config_test.ET.DATASET.COLOR = 1\n",
    "config_test.ET.DATASET.FLIP = 0\n",
    "config_test.ET.DATASET.BLUR = 0\n",
    "config_test.ET.DATASET.GRAY = 0\n",
    "config_test.ET.DATASET.MIXUP = 0\n",
    "config_test.ET.DATASET.CUTOUT = 0\n",
    "config_test.ET.DATASET.CHANNEL6 = 0\n",
    "config_test.ET.DATASET.LABELSMOOTH = 0\n",
    "config_test.ET.DATASET.ROTATION = 0\n",
    "config_test.ET.DATASET.SHIFTs = 64\n",
    "config_test.ET.DATASET.SCALEs = 0.18\n",
    "\n",
    "config_test.ET.DATASET.MIX.DIST = 'beta'\n",
    "config_test.ET.DATASET.MIX.ALPHA = 1.0\n",
    "config_test.ET.DATASET.MIX.BETA = 1.0\n",
    "config_test.ET.DATASET.MIX.MIN = 0\n",
    "config_test.ET.DATASET.MIX.MAX = 1\n",
    "config_test.ET.DATASET.MIX.PROB = 1\n",
    "\n",
    "\n",
    "\n",
    "# LaSOT\n",
    "config_test.ET.DATASET.LASOT.PATH = 'C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\test\\\\LaSOT_cropped\\\\crop511'\n",
    "config_test.ET.DATASET.LASOT.ANNOTATION = 'C:\\\\Users\\\\tommy\\\\ettrack\\\\data\\\\test\\\\LaSOT_cropped\\\\train.json'\n",
    "config_test.ET.DATASET.LASOT.RANGE = 100\n",
    "config_test.ET.DATASET.LASOT.USE = 2002\n",
    "\n",
    "\n",
    "# train\n",
    "config_test.ET.TRAIN.SCRATCH = False\n",
    "config_test.ET.TRAIN.EMA = 0.9998\n",
    "config_test.ET.TRAIN.NEG_WEIGHT = 0.1\n",
    "config_test.ET.TRAIN.GROUP = \"resrchvc\"\n",
    "config_test.ET.TRAIN.EXID = \"setting1\"\n",
    "config_test.ET.TRAIN.MODEL = \"ET\"\n",
    "config_test.ET.TRAIN.RESUME = False\n",
    "config_test.ET.TRAIN.START_EPOCH = 0\n",
    "config_test.ET.TRAIN.END_EPOCH = 50\n",
    "config_test.ET.TRAIN.TEMPLATE_SIZE = 128\n",
    "config_test.ET.TRAIN.SEARCH_SIZE = 256\n",
    "config_test.ET.TRAIN.STRIDE = 16\n",
    "config_test.ET.TRAIN.BATCH = 32\n",
    "config_test.ET.TRAIN.PRETRAIN = 'pretrain.model'\n",
    "config_test.ET.TRAIN.LR_POLICY = 'log'\n",
    "config_test.ET.TRAIN.LR = 0.001\n",
    "config_test.ET.TRAIN.LR_END = 0.00001\n",
    "config_test.ET.TRAIN.MOMENTUM = 0.9\n",
    "config_test.ET.TRAIN.WEIGHT_DECAY = 0.0001\n",
    "config_test.ET.TRAIN.WHICH_USE = ['LASOT']  # VID or 'GOT10K'\n",
    "config_test.ET.TRAIN.FREEZE_LAYER = []\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15512ebf7561620b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lasot_test = OceanDataset(config_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bae460f4884f044e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loader = DataLoader(lasot_test, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d8050399f01ca6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_test = []\n",
    "for i, data in enumerate(train_loader): \n",
    "    with torch.no_grad():\n",
    "        ettracker.eval()\n",
    "        template, search, out_label, reg_label, reg_weight, some_array = data\n",
    "        template = template.to(device)\n",
    "        search = search.to(device)\n",
    "        out_label = out_label.to(device)\n",
    "        reg_label = reg_label.to(device)\n",
    "        reg_weight = reg_weight.to(device)\n",
    "        output = ettracker(template, search, out_label, reg_label, reg_weight)\n",
    "        cls, reg = output\n",
    "        loss = cls + reg\n",
    "        losses_test.append(loss.item())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf0c29aca75c57ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('test_losses.pkl', 'wb') as f:\n",
    "    pickle.dump(losses_test, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fa6fee7b8388e30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a59636262d088309"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_loss_model = ET_Tracker(linear_reg=True)\n",
    "min_loss_model.load_state_dict(torch.load('./ettracker_min.pth'))\n",
    "min_loss_model.to(device)\n",
    "min_loss_model.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67c20dd409791296"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_losses_test = []\n",
    "for i, data in enumerate(train_loader): \n",
    "    with torch.no_grad():\n",
    "        min_loss_model.eval()\n",
    "        template, search, out_label, reg_label, reg_weight, some_array = data\n",
    "        template = template.to(device)\n",
    "        search = search.to(device)\n",
    "        out_label = out_label.to(device)\n",
    "        reg_label = reg_label.to(device)\n",
    "        reg_weight = reg_weight.to(device)\n",
    "        output = min_loss_model(template, search, out_label, reg_label, reg_weight)\n",
    "        cls, reg = output\n",
    "        loss = cls + reg\n",
    "        min_losses_test.append(loss.item())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b4551911bfa93e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('min_loss_test_losses.pkl', 'wb') as f:\n",
    "    pickle.dump(min_losses_test, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b32fe2cb48ecb7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with open(\"min_loss_test_losses.pkl\", \"rb\") as fp:   # Unpickling\n",
    "#     b = pickle.load(fp)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2cfe20a52f0b98f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
